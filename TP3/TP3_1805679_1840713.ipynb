{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rental-sender",
   "metadata": {},
   "source": [
    "INF6804<br>\n",
    "Polytechnique Montréal<br>\n",
    "TP3: Détection et suivi de multiples objets d'intérêt<br>\n",
    "\n",
    "Auteurs:<br>\n",
    "Marc-Olivier Bélanger - 1840713<br>\n",
    "Pierre-Luc Chartier - 1805679"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-advocacy",
   "metadata": {},
   "source": [
    "### Déclarations globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "expired-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.optimize as sci\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import urllib.request as request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "connected-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_NAMES = ['background']\n",
    "label_names = request.urlopen('https://raw.githubusercontent.com/gabilodeau/INF6804/master/utils/coco-labels.txt')\n",
    "for label_name in label_names.readlines():\n",
    "    COCO_NAMES.append(label_name.strip().decode('UTF-8'))\n",
    "\n",
    "IOU_THRESHOLD = 0.5\n",
    "SCORE_THRESHOLD = 0.95\n",
    "\n",
    "source_path = \"/Users/mabelal/Downloads/TP3_data/frames\"\n",
    "\n",
    "model = models.detection.maskrcnn_resnet50_fpn(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-maldives",
   "metadata": {},
   "source": [
    "### Détection des objets (Mask R-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "interior-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img):\n",
    "    preprocess = transforms.Compose([transforms.ToTensor()])\n",
    "    tensors = [preprocess(img)]\n",
    "    \n",
    "    predictions = model(tensors)\n",
    "    boxes = []\n",
    "    \n",
    "    for p in predictions:\n",
    "        for j, score in enumerate(p['scores']):\n",
    "            if score >= SCORE_THRESHOLD:\n",
    "                label = p['labels'][j]\n",
    "                is_cup_or_person = (COCO_NAMES[label] == \"cup\") or (COCO_NAMES[label] == \"person\")\n",
    "\n",
    "                if is_cup_or_person:\n",
    "                    boxes.append(p['boxes'][j])\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-feedback",
   "metadata": {},
   "source": [
    "### Description des objets (Histogramme de couleurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "brilliant-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_color_hist(img, bbox):\n",
    "    roi = (bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3])\n",
    "    mask = np.zeros((img.shape[0],img.shape[1]), np.uint8)\n",
    "    cv2.rectangle(mask,(roi[0],roi[1]),(roi[2],roi[3]),255,-1,8,0);\n",
    "    return cv2.calcHist([img],[0],mask,[64],[0,256])\n",
    "\n",
    "\n",
    "def compare_color_hist(hist1, hist2):\n",
    "    return cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-utility",
   "metadata": {},
   "source": [
    "### Association des données (Algorithme hongrois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "stuffed-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cost_matrix(prev_img, prev_bboxes, current_img, current_bboxes):\n",
    "    cost_matrix = np.zeros((len(prev_bboxes), len(current_bboxes)))\n",
    "    for i in range(0,len(prev_bboxes)):\n",
    "        hist_prev = calc_color_hist(prev_img, prev_bboxes[i])\n",
    "        for j in range(0,len(current_bboxes)):\n",
    "            hist_current = calc_color_hist(current_img, current_bboxes[j])\n",
    "            cost_matrix[i,j] = compare_color_hist(hist_prev, hist_current)\n",
    "    return cost_matrix\n",
    "\n",
    "\n",
    "def associate_data(prev_img, prev_bboxes, current_img, current_bboxes):\n",
    "    cost_matrix = calc_cost_matrix(prev_img, prev_bboxes, current_img, current_bboxes)\n",
    "    \n",
    "    row_ind, col_ind = sci.linear_sum_assignment(cost_matrix)\n",
    "    return row_ind, col_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-amber",
   "metadata": {},
   "source": [
    "### Algorithme principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "statutory-start",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# keep a set of tracked objects \n",
    "# update it as needed e.g. clear the objects undetected since the last n seconds (n*fps frames)\n",
    "tracked_objects = {}\n",
    "\n",
    "# pour chaque image:\n",
    "#  call détection d'objets\n",
    "img = cv2.imread(os.path.join(source_path, \"frame1.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "boxes = detect_objects(img)\n",
    "\n",
    "#test\n",
    "img2 = cv2.imread(os.path.join(source_path, \"frame2.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "b2 = detect_objects(img2)\n",
    "\n",
    "row_ind, col_ind = associate_data(img, boxes, img2, b2)\n",
    "print(row_ind)\n",
    "print(col_ind)\n",
    "###\n",
    "\n",
    "#  call description d'objets pour construire la matrice des coûts d'association\n",
    "#  call algo hongrois et associer les objets\n",
    "\n",
    "#  pour les objets détectés non-associés à cette étape (nouveaux objets ou réapparition)\n",
    "#   update tracked objects (add to set (create their id, set their count to 0) or reset count)\n",
    "\n",
    "#  pour les objets non-détectés à cette itération (in tracked, but not in current_detected)\n",
    "#   update tracked objects (increase count, if count == threshold, remove them)\n",
    "\n",
    "#  write bboxe coordinates of each detected and associated object (i.e. objects in tracked objects with count = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-sigma",
   "metadata": {},
   "source": [
    "### MOT17-11: Forward moving camera in a busy shopping mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul du MOTA en utilisant IoU > 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-narrow",
   "metadata": {},
   "source": [
    "### MOT17-05: Street scene from a moving platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul du MOTA en utilisant IoU > 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-assignment",
   "metadata": {},
   "source": [
    "### MOT17-13 : Filmed from a bus on a busy intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intended-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul du MOTA en utilisant IoU > 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-diana",
   "metadata": {},
   "source": [
    "### Résultats sur la trame fournie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latter-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call algo principal avec les trames des tasses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
